{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7b07a9-2db3-4e08-8bfa-998cb56f4ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b2c5a6-b6e3-403a-80fb-20dc86f3ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "517816e1-7b31-4644-9b07-ff40162b2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c960594e-b250-4a82-8a12-5f342f4fe923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import basename\n",
    "from args import parser\n",
    "import yaml\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from data.utils import update_values\n",
    "\n",
    "from scripts.test_utils import get_dataset, get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83981ca7-a052-4871-9392-958140d1f60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://stackoverflow.com/questions/44542605/python-how-to-get-all-default-values-from-argparse\n",
    "\n",
    "def get_argparse_defaults(parser):\n",
    "    defaults = {}\n",
    "    for action in parser._actions:\n",
    "        if not action.required and action.dest != \"help\":\n",
    "            defaults[action.dest] = action.default\n",
    "    return defaults\n",
    "\n",
    "def get_argparse_required(parser):\n",
    "    required = []\n",
    "    for action in parser._actions:\n",
    "        if action.required:\n",
    "            required.append(action.dest)\n",
    "    return required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d83fe7a-f712-4654-ad49-a396ac628c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default arguments\n",
    "default_args = get_argparse_defaults(parser)\n",
    "args = argparse.Namespace(**default_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f980940d-ec6c-4285-809d-d971df42d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set required and provided arguments\n",
    "\n",
    "args.cfgs_file = 'cfgs/anet.yml'\n",
    "args.split = 'validation'\n",
    "args.epoch=19\n",
    "\n",
    "_id = \"anet-2L-gt-mask\"\n",
    "args.densecap_eval_file = \"./tools/densevid_eval/evaluate.py\"\n",
    "args.start_from = f\"./checkpoint/{_id}/model_epoch_{args.epoch}.t7\"\n",
    "args.id = f\"{_id}-{args.epoch}\"\n",
    "\n",
    "args.val_data_folder = args.split\n",
    "args.batch_size = 1\n",
    "args.cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "169b909c-99fb-4f27-a9fb-906f07da8f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pbagad/install/miniconda3/envs/densecap/lib/python3.6/site-packages/ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "with open(args.cfgs_file, 'r') as handle:\n",
    "    options_yaml = yaml.load(handle)\n",
    "update_values(options_yaml, vars(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "852a1683-81ca-49fe-a928-ff25e9b8b475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(attn_dropout=0.2, batch_size=1, cap_dropout=0.2, cfgs_file='cfgs/anet.yml', cuda=True, d_hidden=2048, d_model=1024, dataset='anet', dataset_file='./data/anet/anet_annotations_trainval.json', densecap_eval_file='./tools/densevid_eval/evaluate.py', densecap_references=['./data/anet/val_1.json', './data/anet/val_2.json'], dur_file='./data/anet/anet_duration_frame.csv', epoch=19, feature_root='./data/anet/', gated_mask=False, id='anet-2L-gt-mask-19', image_feat_size=3072, in_emb_dropout=0.1, kernel_list=[1, 2, 3, 4, 5, 7, 9, 11, 15, 21, 29, 41, 57, 71, 111, 161, 211, 251], learn_mask=False, max_prop_num=500, max_sentence_len=20, min_prop_before_nms=200, min_prop_num=50, n_heads=8, n_layers=2, num_workers=2, pos_thresh=0.7, sampling_sec=0.5, slide_window_size=480, slide_window_stride=20, split='validation', start_from='./checkpoint/anet-2L-gt-mask/model_epoch_19.t7', stride_factor=50, val_data_folder='validation', vis_emb_dropout=0.1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832dde0e-90bf-4bab-bd2a-e9422851454e",
   "metadata": {},
   "source": [
    "### Load dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f278a36a-5d4b-4c2b-872e-3870b0c49788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset\n",
      "\n",
      "\u001b[93m    Warning: no model found for 'en'\u001b[0m\n",
      "\n",
      "    Only loading the 'en' tokenizer.\n",
      "\n",
      "# of words in the vocab: 4563\n",
      "# of sentences in training: 37421, # of sentences in validation: 17505\n",
      "# of training videos: 10009\n",
      "total number of samples (unique videos): 4915\n",
      "total number of sentences: 17499\n"
     ]
    }
   ],
   "source": [
    "print('loading dataset')\n",
    "test_loader, text_proc = get_dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e46dbd14-85a1-464b-925e-144f88dc2d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model\n",
      "Initializing weights from ./checkpoint/anet-2L-gt-mask/model_epoch_19.t7\n"
     ]
    }
   ],
   "source": [
    "print('building model')\n",
    "model = get_model(text_proc, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef70738-aa8a-44b4-81de-50f22588cfeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b38c540d-59ae-40a2-991a-8746cd3cecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_to_second(dur_file, dataset, sampling_sec):\n",
    "    frame_to_second = {}\n",
    "    with open(dur_file) as f:\n",
    "        if dataset == 'anet':\n",
    "            for line in f:\n",
    "                vid_name, vid_dur, vid_frame = [l.strip() for l in line.split(',')]\n",
    "                vid_fps = int(float(vid_frame)*1./int(float(vid_dur)))\n",
    "                frame_to_second[vid_name] = float(vid_dur) * \\\n",
    "                    int(float(vid_frame)*1./int(float(vid_dur)) * sampling_sec)*1./float(vid_frame)\n",
    "            frame_to_second['_0CqozZun3U'] = sampling_sec # a missing video in anet\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    return frame_to_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20deebd3-a961-448b-b3e7-5c4976e20469",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_to_second = get_frame_to_second(\n",
    "    args.dur_file, args.dataset, args.sampling_sec,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a737d435-59d5-4694-ba40-036dd1a67357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anet_annotations_trainval.json\tval_1.json  validation\n",
      "anet_duration_frame.csv\t\tval_2.json\n"
     ]
    }
   ],
   "source": [
    "!ls data/anet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aacbfc75-170e-4229-8fc2-8ae6733eff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/anet/val_1.json\") as f:\n",
    "    annotations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a377217-a10b-4b70-a1a3-f8e7b07172a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4917"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "027316fd-6ce0-441c-85fa-8f3fde8ab2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v_uqiMw7tQ1Cc',\n",
       " 'v_bXdq2zI1Ms0',\n",
       " 'v_FsS_NCZEfaI',\n",
       " 'v_K6Tm5xHkJ5c',\n",
       " 'v_4Lu8ECLHvK4',\n",
       " 'v_HWV_ccmZVPA',\n",
       " 'v_GGSY1Qvo990',\n",
       " 'v_frePM0YGtQE',\n",
       " 'v_JTrwGfPJNzU',\n",
       " 'v_gOniW-yEZ0k']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(annotations.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ca9f1f7-678b-4061-a1d3-f603b896073a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'duration': 184.6,\n",
       " 'timestamps': [[0, 4.61],\n",
       "  [4.61, 82.15],\n",
       "  [45.23, 58.15],\n",
       "  [83.07, 85.84],\n",
       "  [85.84, 148.6],\n",
       "  [148.6, 184.6],\n",
       "  [152.29, 166.14]],\n",
       " 'sentences': ['We see the blue opening screen.',\n",
       "  ' A lady is guiding a young lady through an exercise.',\n",
       "  ' The girl sits down, then gets on one knee and sits back down.',\n",
       "  ' We see a title screen on beige.',\n",
       "  ' The lady gets up from the floor slowly with instructions on the screen.',\n",
       "  ' The lady is sitting on a table and shoes how to sit, and stand slowly holding your abdomen.',\n",
       "  ' The couple behind the lady laugh.']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id = 'v_PLek2e8NlKc'\n",
    "\n",
    "annotations[video_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f726ad1-8922-4f6b-84ea-0de5cff09a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_per_clip(model, loader, annotations, args, debug=False):\n",
    "    model.eval()\n",
    "    densecap_result = defaultdict(list)\n",
    "    prop_result = defaultdict(list)\n",
    "\n",
    "    avg_prop_num = 0\n",
    "    frame_to_second = get_frame_to_second(\n",
    "        args.dur_file, args.dataset, args.sampling_sec,\n",
    "    )\n",
    "    \n",
    "    ground_truth = defaultdict(list)\n",
    "    generated = defaultdict(list)\n",
    "\n",
    "\n",
    "    for data in loader:\n",
    "        # loads entire video\n",
    "        image_feat, original_num_frame, video_prefix = data\n",
    "        # index 0 because batch size is 1\n",
    "        video_id = \"v_\" + basename(video_prefix[0])\n",
    "        \n",
    "        if video_prefix[0].split('/')[-1] not in frame_to_second:\n",
    "            frame_to_second[video_prefix[0].split('/')[-1]] = args.sampling_sec\n",
    "            print(\"cannot find frame_to_second for video {}\".format(video_prefix[0].split('/')[-1]))\n",
    "        sampling_sec = frame_to_second[video_prefix[0].split('/')[-1]] # batch_size has to be 1\n",
    "        \n",
    "        # sample a random clip\n",
    "        num_frames_in_video = original_num_frame[0].item()\n",
    "        fps = int(np.round(1 / sampling_sec, decimals=1))\n",
    "        duration_video = num_frames_in_video / fps\n",
    "        \n",
    "        video_annotations = annotations[video_id]\n",
    "        \n",
    "\n",
    "        iterator = zip(video_annotations[\"timestamps\"], video_annotations[\"sentences\"])\n",
    "        for (clip_start_time, clip_end_time), clip_gt_caption in iterator:\n",
    "            \n",
    "            clip_start_frame = int((clip_start_time / duration_video) * num_frames_in_video)\n",
    "            clip_end_frame = int((clip_end_time / duration_video) * num_frames_in_video)\n",
    "            \n",
    "            image_feat_clip = image_feat[:, clip_start_frame:clip_end_frame, :]\n",
    "            original_num_frame[0] = clip_end_frame - clip_start_frame\n",
    "\n",
    "            # predict caption for clip (segment)\n",
    "            with torch.no_grad():\n",
    "                image_feat_clip = Variable(image_feat_clip)\n",
    "\n",
    "                # ship data to gpu\n",
    "                if args.cuda:\n",
    "                    image_feat_clip = image_feat_clip.cuda()\n",
    "\n",
    "                dtype = image_feat_clip.data.type()\n",
    "\n",
    "                all_proposal_results = model.inference(image_feat_clip,\n",
    "                                                       original_num_frame,\n",
    "                                                       sampling_sec,\n",
    "                                                       args.min_prop_num,\n",
    "                                                       args.max_prop_num,\n",
    "                                                       args.min_prop_before_nms,\n",
    "                                                       args.pos_thresh,\n",
    "                                                       args.stride_factor,\n",
    "                                                       entire_video=True,\n",
    "                                                       gated_mask=args.gated_mask)\n",
    "                clip_pred_caption = all_proposal_results[0][0][-1]\n",
    "            \n",
    "            \n",
    "                ground_truth[video_id].append(\n",
    "                    {\n",
    "                        \"caption\": clip_gt_caption,\n",
    "                        \"start_time\": clip_start_time,\n",
    "                        \"end_time\": clip_end_time,\n",
    "                        \"video_id\": video_id,\n",
    "                        \"fps\": fps,\n",
    "                    }\n",
    "                )\n",
    "                generated[video_id].append(\n",
    "                    {\n",
    "                        \"caption\": clip_pred_caption,\n",
    "                        \"start_time\": clip_start_time,\n",
    "                        \"start_frame\": clip_start_frame,\n",
    "                        \"end_time\": clip_end_time,\n",
    "                        \"end_frame\": clip_end_frame,\n",
    "                        \"video_id\": video_id,\n",
    "                        \"fps\": fps,\n",
    "                    }\n",
    "                )\n",
    "        \n",
    "        if debug:\n",
    "            break\n",
    "    \n",
    "    return ground_truth, generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cfea327-811f-4673-9d71-32d07cdb5250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping kernel sizes greater than 11\n",
      "Processing time for tIoU: 0.02, mask: 0.00, caption: 0.11\n",
      "skipping kernel sizes greater than 161\n",
      "Processing time for tIoU: 0.05, mask: 0.00, caption: 0.11\n",
      "skipping kernel sizes greater than 29\n",
      "Processing time for tIoU: 0.06, mask: 0.00, caption: 0.11\n",
      "skipping kernel sizes greater than 7\n",
      "Processing time for tIoU: 0.00, mask: 0.00, caption: 0.11\n",
      "skipping kernel sizes greater than 161\n",
      "Processing time for tIoU: 0.05, mask: 0.00, caption: 0.11\n",
      "skipping kernel sizes greater than 111\n",
      "Processing time for tIoU: 0.05, mask: 0.00, caption: 0.11\n",
      "skipping kernel sizes greater than 29\n",
      "Processing time for tIoU: 0.07, mask: 0.00, caption: 0.11\n"
     ]
    }
   ],
   "source": [
    "ground_truth, generated = validate_per_clip(model, test_loader, annotations, args, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00786dc5-7139-41a9-be42-76914c30b3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'v_PLek2e8NlKc': [{'caption': 'We see the blue opening screen.',\n",
       "               'start_time': 0,\n",
       "               'end_time': 4.61,\n",
       "               'video_id': 'v_PLek2e8NlKc',\n",
       "               'fps': 2},\n",
       "              {'caption': ' A lady is guiding a young lady through an exercise.',\n",
       "               'start_time': 4.61,\n",
       "               'end_time': 82.15,\n",
       "               'video_id': 'v_PLek2e8NlKc',\n",
       "               'fps': 2},\n",
       "              {'caption': ' The girl sits down, then gets on one knee and sits back down.',\n",
       "               'start_time': 45.23,\n",
       "               'end_time': 58.15,\n",
       "               'video_id': 'v_PLek2e8NlKc',\n",
       "               'fps': 2},\n",
       "              {'caption': ' We see a title screen on beige.',\n",
       "               'start_time': 83.07,\n",
       "               'end_time': 85.84,\n",
       "               'video_id': 'v_PLek2e8NlKc',\n",
       "               'fps': 2},\n",
       "              {'caption': ' The lady gets up from the floor slowly with instructions on the screen.',\n",
       "               'start_time': 85.84,\n",
       "               'end_time': 148.6,\n",
       "               'video_id': 'v_PLek2e8NlKc',\n",
       "               'fps': 2},\n",
       "              {'caption': ' The lady is sitting on a table and shoes how to sit, and stand slowly holding your abdomen.',\n",
       "               'start_time': 148.6,\n",
       "               'end_time': 184.6,\n",
       "               'video_id': 'v_PLek2e8NlKc',\n",
       "               'fps': 2},\n",
       "              {'caption': ' The couple behind the lady laugh.',\n",
       "               'start_time': 152.29,\n",
       "               'end_time': 166.14,\n",
       "               'video_id': 'v_PLek2e8NlKc',\n",
       "               'fps': 2}]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43f2debe-5968-4de1-bc58-565eb0ae313d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'v_PLek2e8NlKc': [{'caption': 'a man is standing in a <unk> in a <unk>',\n",
       "               'start_time': 0,\n",
       "               'start_frame': 0,\n",
       "               'end_time': 4.61,\n",
       "               'end_frame': 9,\n",
       "               'video_id': 'v_PLek2e8NlKc',\n",
       "               'fps': 2},\n",
       "              {'caption': 'a man is standing in a room in a room',\n",
       "               'start_time': 4.61,\n",
       "               'start_frame': 9,\n",
       "               'end_time': 82.15,\n",
       "               'end_frame': 164,\n",
       "               'video_id': 'v_PLek2e8NlKc',\n",
       "               'fps': 2},\n",
       "              {'caption': 'a man is standing in a room in a <unk>',\n",
       "               'start_time': 45.23,\n",
       "               'start_frame': 90,\n",
       "               'end_time': 58.15,\n",
       "               'end_frame': 116,\n",
       "               'video_id': 'v_PLek2e8NlKc',\n",
       "               'fps': 2},\n",
       "              {'caption': 'a close up of a video of a video of a video of an intro intro intro intro',\n",
       "               'start_time': 83.07,\n",
       "               'start_frame': 166,\n",
       "               'end_time': 85.84,\n",
       "               'end_frame': 171,\n",
       "               'video_id': 'v_PLek2e8NlKc',\n",
       "               'fps': 2},\n",
       "              {'caption': 'a woman is sitting in a <unk>',\n",
       "               'start_time': 85.84,\n",
       "               'start_frame': 171,\n",
       "               'end_time': 148.6,\n",
       "               'end_frame': 297,\n",
       "               'video_id': 'v_PLek2e8NlKc',\n",
       "               'fps': 2},\n",
       "              {'caption': 'a woman is sitting in a <unk>',\n",
       "               'start_time': 148.6,\n",
       "               'start_frame': 297,\n",
       "               'end_time': 184.6,\n",
       "               'end_frame': 369,\n",
       "               'video_id': 'v_PLek2e8NlKc',\n",
       "               'fps': 2},\n",
       "              {'caption': 'a woman is sitting in a <unk>',\n",
       "               'start_time': 152.29,\n",
       "               'start_frame': 304,\n",
       "               'end_time': 166.14,\n",
       "               'end_frame': 332,\n",
       "               'video_id': 'v_PLek2e8NlKc',\n",
       "               'fps': 2}]})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551230cb-a52c-4ecc-88f0-d91e1489c1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
